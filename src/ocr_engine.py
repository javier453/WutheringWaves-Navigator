#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCR Engine for WutheringWaves Navigator
é›†æˆçš„OCRåæ ‡è¯†åˆ«å¼•æ“
"""

import time
import logging
import numpy as np
import cv2
from typing import Optional, List, Tuple, Dict, Any
from pathlib import Path
import torch
from ultralytics import YOLO
import math
import re
import traceback
from PySide6.QtCore import QThread, Signal


def cluster_detections_to_rich_clusters(detections: list, gap_threshold: float = 0.5) -> list[dict]:
    """
    æ”¹è¿›çš„èšç±»ç®—æ³•ï¼šæ™ºèƒ½è¯†åˆ«ç©ºæ ¼å’Œåˆ†éš”ç¬¦
    èƒ½å¤Ÿæ­£ç¡®åŒºåˆ† '2591 1891,5189' ä¸­çš„ç©ºæ ¼åˆ†éš”
    """
    if not detections:
        return []
    
    # æŒ‰xåæ ‡ä»å·¦åˆ°å³æ’åº
    detections.sort(key=lambda d: d['bbox'][0])
    
    # è®¡ç®—å½“å‰æ£€æµ‹æ‰¹æ¬¡ä¸­æ‰€æœ‰å­—ç¬¦çš„å¹³å‡å®½åº¦
    total_width = 0
    valid_char_count = 0
    for detection in detections:
        char = OCRWorker._class_id_to_char_static(detection['class'])
        if char and (char.isdigit() or char in ['-', ',']):  # åªç»Ÿè®¡æ•°å­—ã€è´Ÿå·ã€é€—å·çš„å®½åº¦
            width = detection['bbox'][2] - detection['bbox'][0]
            if width > 0:
                total_width += width
                valid_char_count += 1
    
    if valid_char_count == 0:
        return []
    
    # å¹³å‡å­—ç¬¦å®½åº¦
    avg_char_width = total_width / valid_char_count
    
    import logging
    logger = logging.getLogger(__name__)
    logger.debug(f"[SMART_CLUSTERING] å¹³å‡å­—ç¬¦å®½åº¦: {avg_char_width:.2f}, æ£€æµ‹åˆ°{valid_char_count}ä¸ªæœ‰æ•ˆå­—ç¬¦")
    
    # è®¡ç®—æ‰€æœ‰é—´éš™ï¼Œç”¨äºæ™ºèƒ½åˆ†éš”ç¬¦åˆ¤æ–­
    gaps = []
    for i in range(1, len(detections)):
        prev_x2 = detections[i-1]['bbox'][2]
        curr_x1 = detections[i]['bbox'][0]
        gap = curr_x1 - prev_x2
        gaps.append(gap)
    
    # ä½¿ç”¨ä¿å®ˆçš„é˜ˆå€¼æ¥é¿å…è¿‡åº¦åˆ†å‰²
    if gaps:
        # æ–¹æ³•1: åŸºäºå¹³å‡å­—ç¬¦å®½åº¦çš„å€æ•° - ä½¿ç”¨æ›´å¤§çš„å€æ•°é¿å…åˆ†å‰²æ•°å­—
        threshold_1 = avg_char_width * 1.8  # æé«˜é˜ˆå€¼ï¼Œé¿å…æŠŠæ•°å­—å†…éƒ¨åˆ†å‰²å¼€
        
        # æ–¹æ³•2: åŸºäºé—´éš™çš„ç»Ÿè®¡ç‰¹å¾
        gaps_sorted = sorted(gaps)
        if len(gaps_sorted) > 2:
            # ä½¿ç”¨75åˆ†ä½æ•°çš„2å€ä½œä¸ºé˜ˆå€¼ï¼Œæ›´ä¿å®ˆ
            percentile_75_index = int(len(gaps_sorted) * 0.75)
            percentile_75_gap = gaps_sorted[percentile_75_index]
            threshold_2 = percentile_75_gap * 2.0
        else:
            threshold_2 = threshold_1
        
        # ä½¿ç”¨è¾ƒå¤§çš„é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦åˆ†éš”
        separation_threshold = max(threshold_1, threshold_2)
        
        logger.debug(f"[SMART_CLUSTERING] åˆ†éš”é˜ˆå€¼: {separation_threshold:.2f} (æ–¹æ³•1:{threshold_1:.2f}, æ–¹æ³•2:{threshold_2:.2f})")
    else:
        separation_threshold = avg_char_width * 1.8
    
    clusters = []
    current_word = ""
    current_detections_list = []
    last_x2 = None
    
    for detection in detections:
        char = OCRWorker._class_id_to_char_static(detection['class'])
        if not char:
            continue
            
        x1, y1, x2, y2 = detection['bbox']
        
        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªå­—ç¬¦ï¼Œç›´æ¥æ·»åŠ 
        if last_x2 is None:
            current_word = char
            current_detections_list = [detection]
            last_x2 = x2
            continue
        
        # è®¡ç®—é—´éš™
        gap = x1 - last_x2
        
        # æ™ºèƒ½åˆ†éš”åˆ¤æ–­
        should_separate = False
        
        # æ ‡å‡†1: é—´éš™è¶…è¿‡åˆ†éš”é˜ˆå€¼
        if gap > separation_threshold:
            should_separate = True
            logger.debug(f"[SMART_CLUSTERING] æ ‡å‡†1è§¦å‘: é—´éš™{gap:.2f} > é˜ˆå€¼{separation_threshold:.2f}")
        
        # æ ‡å‡†2: æ£€æµ‹æ˜æ˜¾çš„ç©ºæ ¼åˆ†éš”ï¼ˆé—´éš™æ˜¾è‘—å¤§äºå­—ç¬¦å®½åº¦ï¼‰
        if gap > avg_char_width * 2.5:  # 2.5å€å­—ç¬¦å®½åº¦æ‰è®¤ä¸ºæ˜¯æ˜æ˜¾ç©ºæ ¼
            should_separate = True
            logger.debug(f"[SMART_CLUSTERING] æ ‡å‡†2è§¦å‘: æ£€æµ‹åˆ°ç©ºæ ¼åˆ†éš” {gap:.2f} > {avg_char_width * 2.5:.2f}")
        
        # æ ‡å‡†3: åæ ‡é€»è¾‘åˆ†éš” - æ›´ä¸¥æ ¼ï¼Œé¿å…è¯¯åˆ†å‰²
        # åªæœ‰åœ¨é—´éš™éå¸¸å¤§çš„æƒ…å†µä¸‹ï¼Œä¸”å‰é¢æ˜¯å®Œæ•´çš„è¾ƒé•¿æ•°å­—æ—¶æ‰åˆ†å‰²
        if (current_word.replace(',', '').replace('-', '').isdigit() and len(current_word) >= 4 and 
            char.isdigit() and gap > avg_char_width * 2.0):  # æé«˜åˆ°2.0å€
            should_separate = True
            logger.debug(f"[SMART_CLUSTERING] æ ‡å‡†3è§¦å‘: æ•°å­—åˆ†éš”é€»è¾‘ '{current_word}' | '{char}'")
        
        if should_separate:
            # ä¿å­˜å½“å‰èšç±»
            if current_word:
                clusters.append({'word': current_word, 'detections': current_detections_list})
            # å¼€å§‹æ–°èšç±»
            current_word = char
            current_detections_list = [detection]
        else:
            # ç»§ç»­å½“å‰èšç±»
            current_word += char
            current_detections_list.append(detection)
        
        last_x2 = x2
    
    # æ·»åŠ æœ€åä¸€ä¸ªèšç±»
    if current_word:
        clusters.append({'word': current_word, 'detections': current_detections_list})
    
    logger.debug(f"[SMART_CLUSTERING] èšç±»ç»“æœ: {[cluster['word'] for cluster in clusters]}")
    
    return clusters




def find_best_coordinate_cluster(clusters: list[dict]) -> tuple[dict | None, list[dict]]:
    """
    é‡å†™çš„åæ ‡é€‰æ‹©ç®—æ³•ï¼šå»é™¤è¯­ä¹‰è¯„åˆ†ï¼Œç›´æ¥åŒ¹é…åæ ‡æ ¼å¼
    åæ ‡æ ¼å¼ï¼šx,y,zï¼ˆæ¯ä¸ªåˆ†é‡å¯èƒ½ä¸ºæ­£æ•°æˆ–è´Ÿæ•°ï¼Œä½æ•°1-7ä½ä¸å®šï¼‰
    """
    import logging
    logger = logging.getLogger(__name__)
    
    # åæ ‡æ ¼å¼æ­£åˆ™ï¼šåŒ¹é… x,y,z æ ¼å¼ï¼Œæ¯ä¸ªåˆ†é‡å¯æ­£å¯è´Ÿï¼Œä½æ•°1-7ä½
    coord_pattern = re.compile(r'^-?\d{1,7},-?\d{1,7},-?\d{1,7}')
    
    best_cluster = None
    selection_details = []
    
    for cluster in clusters:
        word = cluster['word']
        cleaned_word = word.replace(" ", "").replace("\t", "")
        
        logger.debug(f"[COORD_SELECTION] æ£€æŸ¥èšç±»: '{cleaned_word}'")
        
        # è®°å½•é€‰æ‹©è¯¦æƒ…
        detail = {
            'word': word,
            'cleaned': cleaned_word,
            'matched': False,
            'reason': ""
        }
        
        # ç›´æ¥åŒ¹é…åæ ‡æ ¼å¼
        if coord_pattern.match(cleaned_word):
            logger.debug(f"[COORD_SELECTION] æ‰¾åˆ°åæ ‡æ ¼å¼åŒ¹é…: '{cleaned_word}'")
            detail['matched'] = True
            detail['reason'] = "åŒ¹é…åæ ‡æ ¼å¼"
            
            # å¦‚æœè¿˜æ²¡æœ‰é€‰ä¸­çš„èšç±»ï¼Œæˆ–è€…å½“å‰èšç±»æ›´é•¿ï¼ˆæ›´å®Œæ•´ï¼‰ï¼Œåˆ™é€‰æ‹©å®ƒ
            if best_cluster is None or len(cleaned_word) > len(best_cluster['word'].replace(" ", "")):
                best_cluster = cluster
                logger.debug(f"[COORD_SELECTION] é€‰ä¸­æ–°çš„æœ€ä½³èšç±»: '{cleaned_word}'")
        else:
            detail['reason'] = "ä¸åŒ¹é…åæ ‡æ ¼å¼"
        
        selection_details.append(detail)
    
    if best_cluster:
        logger.debug(f"[COORD_SELECTION] æœ€ç»ˆé€‰æ‹©: '{best_cluster['word']}'")
    else:
        logger.debug(f"[COORD_SELECTION] æœªæ‰¾åˆ°åŒ¹é…çš„åæ ‡æ ¼å¼")
    
    return best_cluster, selection_details


class RecognitionState:
    """Recognition states for the state machine"""
    LOCKED = "LOCKED"
    LOST = "LOST"
    SEARCHING = "SEARCHING"


class OCRWorker(QThread):
    """
    OCR Worker implementing advanced predictive tracking algorithm
    
    This worker runs YOLOv8 model on CPU and provides highly accurate coordinate
    tracking with state management and dynamic template adaptation.
    """
    
    # Static class names for global function access
    _CLASS_NAMES_STATIC = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', ':', '-']
    
    # Qt Signals
    coordinates_detected = Signal(int, int, int)  # x, y, z coordinates
    recognition_state_changed = Signal(str)  # LOCKED, LOST, SEARCHING
    error_occurred = Signal(str)  # Error message
    ocr_output_updated = Signal(str)  # Raw OCR output text
    
    def __init__(self, config_dict=None, capture_callback=None):
        """
        Initialize OCR Worker
        
        Args:
            config_dict: Dictionary containing configuration parameters (optional)
            capture_callback: Function to capture screen regions (optional)
        """
        super().__init__()
        self.config_dict = config_dict or {}
        self.capture_callback = capture_callback
        self.logger = logging.getLogger(__name__)
        
        # Worker control
        self.is_running = False
        self.should_stop = False
        
        # YOLOv8 model
        self.model = None
        
        # Class names mapping
        self.class_names = self._load_class_names()
        
        # Advanced tracking algorithm state variables
        self.recognition_state = RecognitionState.SEARCHING
        self.last_valid_coord = None  # (x, y, z) tuple
        self.last_valid_detections = None  # Dynamic tracking template
        self.consecutive_failures = 0
        
        # Configurable parameters (loaded from config dict)
        config = self.config_dict
        advanced_settings = config.get('advanced_ocr_settings', {})
        
        self.confidence_threshold = config.get('confidence_threshold', 0.45)
        self.max_speed_threshold = advanced_settings.get('max_speed_threshold', 1000)
        self.ema_alpha = advanced_settings.get('ema_alpha', 0.3)
        self.lost_threshold_frames = advanced_settings.get('lost_threshold_frames', 5)
        self.z_axis_threshold = advanced_settings.get('z_axis_threshold', 50)
        
        # OCR capture area and interval
        self.capture_area = None
        self.ocr_interval = 1000  # milliseconds
        self.target_window_name = ""  # Target window name for screenshot
        
        self.logger.info("OCRå·¥ä½œçº¿ç¨‹åˆå§‹åŒ–å®Œæˆ")
    
    def set_capture_callback(self, capture_callback):
        """Set screen capture callback function
        
        Args:
            capture_callback: Function that captures screen region
                             Should accept: (x, y, width, height, mode, target_window_name)
                             Should return: numpy array of captured image or None if failed
        """
        self.capture_callback = capture_callback
    
    def _parse_and_validate_from_detections(self, detections: List[Dict]) -> Tuple[bool, Optional[Tuple[int, int, int]]]:
        """
        é‡å†™çš„åæ ‡è§£æç®—æ³•ï¼šç®€åŒ–è§£æé€»è¾‘ï¼Œæ”¯æŒ1-7ä½åæ ‡
        ä»æ£€æµ‹åˆ—è¡¨ä¸­ç²¾å‡†æå–xyzåæ ‡å€¼
        """
        try:
            if not detections:
                return False, None
            
            # æŒ‰xåæ ‡æ’åºå¹¶æ‹¼æ¥å­—ç¬¦ä¸²
            sorted_detections = sorted(detections, key=lambda d: d['bbox'][0])
            coord_str = "".join([OCRWorker._class_id_to_char_static(d['class']) or "" for d in sorted_detections])
            
            self.logger.debug(f"[COORD_PARSE] åŸå§‹å­—ç¬¦ä¸²: '{coord_str}'")
            
            # ç§»é™¤æ—¶é—´æˆ³éƒ¨åˆ†
            coord_str_cleaned = self._remove_timestamp_from_coord_string(coord_str)
            self.logger.debug(f"[COORD_PARSE] æ¸…ç†åå­—ç¬¦ä¸²: '{coord_str_cleaned}'")
            
            # å‘å°„OCRè¾“å‡ºä¿¡å·
            self.ocr_output_updated.emit(f"è¯†åˆ«ç»“æœ: {coord_str_cleaned}")
            
            # ç²¾å‡†æå–åæ ‡ï¼šæ”¯æŒ1-7ä½æ•°å­—ï¼Œå¯èƒ½ä¸ºè´Ÿæ•°
            coord_pattern = re.compile(r'^(-?\d{1,7}),(-?\d{1,7}),(-?\d{1,7})')
            match = coord_pattern.match(coord_str_cleaned.strip())
            
            if match:
                try:
                    x, y, z = int(match.group(1)), int(match.group(2)), int(match.group(3))
                    self.logger.debug(f"[COORD_PARSE] æå–åæ ‡: ({x}, {y}, {z})")
                    
                    # æ‰©å¤§èŒƒå›´éªŒè¯ï¼šæ”¯æŒ7ä½æ•°å­—ï¼ŒèŒƒå›´Â±9999999
                    max_coord_value = 9999999
                    if all(abs(c) <= max_coord_value for c in [x, y, z]):
                        self.logger.debug(f"[COORD_PARSE] åæ ‡éªŒè¯é€šè¿‡: ({x}, {y}, {z})")
                        parse_result = f"åæ ‡: ({x}, {y}, {z})"
                        self.ocr_output_updated.emit(parse_result)
                        return True, (x, y, z)
                    else:
                        self.logger.debug(f"[COORD_PARSE] åæ ‡è¶…å‡ºèŒƒå›´(Â±{max_coord_value}): ({x}, {y}, {z})")
                        self.ocr_output_updated.emit(f"åæ ‡è¶…å‡ºèŒƒå›´: ({x}, {y}, {z})")
                        
                except ValueError as e:
                    self.logger.debug(f"[COORD_PARSE] æ•°å€¼è½¬æ¢å¤±è´¥: {e}")
                    self.ocr_output_updated.emit(f"æ•°å€¼è½¬æ¢é”™è¯¯: {coord_str_cleaned}")
            else:
                self.logger.debug(f"[COORD_PARSE] æ­£åˆ™åŒ¹é…å¤±è´¥: '{coord_str_cleaned}'")
                self.ocr_output_updated.emit(f"æ ¼å¼ä¸åŒ¹é…: {coord_str_cleaned}")
                
        except Exception as e:
            self.logger.error(f"[COORD_PARSE] è§£æå¼‚å¸¸: {e}")
            self.ocr_output_updated.emit(f"è§£æé”™è¯¯: {str(e)}")
            return False, None
            
        return False, None
    
    def _remove_timestamp_from_coord_string(self, coord_str: str) -> str:
        """
        ç²¾ç¡®çš„æ—¶é—´æˆ³ç§»é™¤ç®—æ³•ï¼šåªå¿½ç•¥202x-æˆ–203x-æ ¼å¼çš„æ—¶é—´æˆ³
        ç”¨äºé¿å…è¯¯åˆ¤zè½´åæ ‡ï¼ˆå¦‚z=20ï¼‰ä¸ºæ—¶é—´æˆ³
        """
        self.logger.debug(f"[TIMESTAMP_REMOVAL] è¾“å…¥å­—ç¬¦ä¸²: '{coord_str}'")
        
        # ç²¾ç¡®åŒ¹é…æ—¶é—´æˆ³æ ¼å¼ï¼š202x-æˆ–203x-ï¼ˆå¹´ä»½åå¿…é¡»è·Ÿç ´æŠ˜å·ï¼‰
        # è¿™æ ·å¯ä»¥åŒºåˆ†zè½´åæ ‡20å’Œæ—¶é—´æˆ³2025-
        timestamp_pattern = re.compile(r'20[23]\d-')
        match = timestamp_pattern.search(coord_str)
        
        if match:
            timestamp_start = match.start()
            timestamp_str = match.group()
            
            self.logger.debug(f"[TIMESTAMP_REMOVAL] æ£€æµ‹åˆ°æ—¶é—´æˆ³æ ¼å¼: {timestamp_str} åœ¨ä½ç½® {timestamp_start}, å¼ºåˆ¶æˆªæ–­")
            
            # å¼ºåˆ¶æˆªæ–­ï¼šå¿½ç•¥æ—¶é—´æˆ³åŠå…¶åé¢çš„æ‰€æœ‰å†…å®¹
            result = coord_str[:timestamp_start].rstrip()
            self.logger.debug(f"[TIMESTAMP_REMOVAL] æ—¶é—´æˆ³æˆªæ–­ç»“æœ: '{result}'")
            return result
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸¦ç ´æŠ˜å·çš„æ—¶é—´æˆ³ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç©ºæ ¼åˆ†éš”çš„æ—¶é—´æˆ³éƒ¨åˆ†
        # åæ ‡æ ¼å¼ï¼š"-xxxx,-yyyy,-zzzz  yyyy-mm-dd hh:mm:ss"
        # å¯»æ‰¾ä¸¤ä¸ªæˆ–æ›´å¤šè¿ç»­ç©ºæ ¼ï¼Œè®¤ä¸ºæ˜¯åæ ‡å’Œæ—¶é—´æˆ³çš„åˆ†éš”
        space_split = re.split(r'\s{2,}', coord_str, maxsplit=1)
        if len(space_split) > 1:
            result = space_split[0].strip()
            self.logger.debug(f"[TIMESTAMP_REMOVAL] é€šè¿‡ç©ºæ ¼åˆ†éš”ç§»é™¤æ—¶é—´æˆ³: '{result}'")
            return result
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å•ç‹¬çš„å››ä½å¹´ä»½ï¼ˆæ²¡æœ‰ç ´æŠ˜å·ï¼‰åœ¨å­—ç¬¦ä¸²æœ«å°¾
        # è¿™ç§æƒ…å†µå¯èƒ½æ˜¯å¹´ä»½ä¿¡æ¯ï¼Œä½†ä¸ä¼šè¯¯åˆ¤zè½´åæ ‡
        year_only_pattern = re.compile(r'\s+20[23]\d$')
        if year_only_pattern.search(coord_str):
            result = year_only_pattern.sub('', coord_str).strip()
            self.logger.debug(f"[TIMESTAMP_REMOVAL] ç§»é™¤æœ«å°¾å¹´ä»½: '{result}'")
            return result
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³æ ‡è¯†ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
        self.logger.debug(f"[TIMESTAMP_REMOVAL] æœªæ‰¾åˆ°æ—¶é—´æˆ³æ ‡è¯†ï¼Œè¿”å›åŸå­—ç¬¦ä¸²")
        return coord_str
    
    @staticmethod
    def _class_id_to_char_static(class_id: int) -> str | None:
        try:
            if 0 <= class_id < len(OCRWorker._CLASS_NAMES_STATIC):
                return OCRWorker._CLASS_NAMES_STATIC[class_id]
            return None
        except:
            return None
    
    def _load_class_names(self) -> List[str]:
        """
        Load class names from models/class_names.txt
        
        Returns:
            List of class names where index corresponds to class ID
        """
        try:
            class_names_path = Path("models/class_names.txt")
            
            if not class_names_path.exists():
                self.logger.error(f"ç±»åˆ«åç§°æ–‡ä»¶ä¸å­˜åœ¨: {class_names_path}")
                # Fallback to hardcoded mapping
                class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', ':', '-']
                OCRWorker._CLASS_NAMES_STATIC = class_names
                return class_names
            
            with open(class_names_path, 'r', encoding='utf-8') as f:
                class_names = [line.strip() for line in f.readlines() if line.strip()]
            
            self.logger.info(f"æˆåŠŸåŠ è½½ç±»åˆ«åç§°: {len(class_names)} ä¸ªç±»åˆ«")
            OCRWorker._CLASS_NAMES_STATIC = class_names
            return class_names
            
        except Exception as e:
            self.logger.error(f"åŠ è½½ç±»åˆ«åç§°å¤±è´¥: {e}")
            # Fallback to hardcoded mapping
            class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', ':', '-']
            OCRWorker._CLASS_NAMES_STATIC = class_names
            return class_names
    
    def load_model(self, model_path=None) -> bool:
        """
        Load YOLOv8 coordinate recognition model
        
        Args:
            model_path: Path to the YOLO model file. If None, uses default or config value.
        
        Returns:
            True if model loaded successfully, False otherwise
        """
        try:
            if model_path is None:
                model_path = self.config_dict.get('model_path', "models/coord_ocr.pt")
            
            model_path = Path(model_path)
            
            if not model_path.exists():
                error_msg = f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}"
                self.logger.error(error_msg)
                self.error_occurred.emit(error_msg)
                return False
            
            # Load model and force CPU usage
            self.model = YOLO(str(model_path))
            self.model.to('cpu')  # Force CPU inference as specified
            
            self.logger.info(f"YOLOv8æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            return True
            
        except Exception as e:
            error_msg = f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}"
            self.logger.error(error_msg)
            self.error_occurred.emit(error_msg)
            return False
    
    def load_settings(self):
        """Load settings from configuration dictionary"""
        config = self.config_dict
        
        # Load OCR capture area
        ocr_area = config.get('ocr_capture_area', {})
        self.capture_area = {
            'x': ocr_area.get('x', 100),
            'y': ocr_area.get('y', 100),
            'width': ocr_area.get('width', 200),
            'height': ocr_area.get('height', 50)
        }
        
        # Load OCR interval
        self.ocr_interval = config.get('ocr_interval', 1000)
        
        # Load target window name (if using window-specific capture)
        self.target_window_name = config.get('target_window_name', '')
        
        self.logger.info(f"OCRè®¾ç½®åŠ è½½å®Œæˆ: åŒºåŸŸ{self.capture_area}, é—´éš”{self.ocr_interval}ms")
    
    def start_recognition(self):
        """Start the OCR recognition process"""
        if not self.is_running:
            self.should_stop = False
            self.start()
            self.logger.info("OCRè¯†åˆ«å¯åŠ¨")
    
    def stop_recognition(self):
        """Stop the OCR recognition process"""
        if self.is_running:
            self.should_stop = True
            self.wait(5000)  # Wait up to 5 seconds for thread to finish
            self.logger.info("OCRè¯†åˆ«åœæ­¢")
    
    def update_confidence_threshold(self, threshold: float):
        """Update confidence threshold dynamically"""
        self.confidence_threshold = threshold
        self.logger.info(f"ç½®ä¿¡ç‡é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold:.2f}")
    
    def update_interval(self, interval: int):
        """Update OCR recognition interval dynamically"""
        self.ocr_interval = interval
        self.logger.info(f"OCRè¯†åˆ«é—´éš”å·²æ›´æ–°ä¸º: {interval}ms")
    
    def get_current_state(self) -> str:
        """Get current recognition state"""
        return self.recognition_state
    
    def update_advanced_parameters(self, params: Dict[str, Any]):
        """Update advanced OCR parameters dynamically"""
        try:
            if 'confidence_threshold' in params:
                self.confidence_threshold = params['confidence_threshold']
            
            if 'max_speed_threshold' in params:
                self.max_speed_threshold = params['max_speed_threshold']
            
            if 'ema_alpha' in params:
                self.ema_alpha = params['ema_alpha']
            
            if 'lost_threshold_frames' in params:
                self.lost_threshold_frames = params['lost_threshold_frames']
            
            if 'z_axis_threshold' in params:
                self.z_axis_threshold = params['z_axis_threshold']
            
            self.logger.info(f"é«˜çº§OCRå‚æ•°å·²æ›´æ–°: {params}")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°é«˜çº§OCRå‚æ•°å¤±è´¥: {e}")
    
    def run(self):
        """Main thread execution loop"""
        self.is_running = True
        
        # Load model and settings
        if not self.load_model():
            self.ocr_output_updated.emit("âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥models/coord_ocr.ptæ–‡ä»¶")
            self.error_occurred.emit("OCRæ¨¡å‹åŠ è½½å¤±è´¥")
            self.is_running = False
            return
        
        self.load_settings()
        
        # Reset state
        self.recognition_state = RecognitionState.SEARCHING
        self.last_valid_coord = None
        self.last_valid_detections = None
        self.consecutive_failures = 0
        
        # Emit initial state
        self.recognition_state_changed.emit(self.recognition_state)
        
        # å‘å°„å¯åŠ¨ä¿¡æ¯
        self.ocr_output_updated.emit("ğŸš€ OCRè¯†åˆ«å·²å¯åŠ¨ï¼Œæ­£åœ¨æœç´¢åæ ‡...")
        
        self.logger.info("OCRè¯†åˆ«å¾ªç¯å¼€å§‹")
        
        while not self.should_stop:
            try:
                frame_start_time = time.time()
                
                # æˆªå›¾
                screenshot = self._capture_ocr_region()
                if screenshot is None:
                    self.ocr_output_updated.emit("âš  æˆªå›¾å¤±è´¥ï¼Œè¯·æ£€æŸ¥OCRåŒºåŸŸè®¾ç½®")
                    self.msleep(self.ocr_interval)
                    continue
                
                # æ¨¡å‹æ¨ç†
                detections = self._run_yolo_inference(screenshot)
                
                # åº”ç”¨è·Ÿè¸ªç®—æ³•
                success, final_coords = self._apply_tracking_algorithm(detections)
                
                # Calculate sleep time to maintain consistent interval
                processing_time = (time.time() - frame_start_time) * 1000
                sleep_time = max(0, self.ocr_interval - processing_time)
                self.msleep(int(sleep_time))
                
            except Exception as e:
                error_msg = f"OCRè¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}"
                self.logger.error(error_msg)
                self.error_occurred.emit(error_msg)
                self.msleep(self.ocr_interval)
        
        self.is_running = False
        self.logger.info("OCRè¯†åˆ«å¾ªç¯ç»“æŸ")
    
    def _capture_ocr_region(self) -> Optional[np.ndarray]:
        """Capture the OCR region from screen"""
        try:
            if self.capture_callback is None:
                self.logger.error("No capture callback provided")
                return None
            
            # Get screenshot mode from config (optional)
            config = self.config_dict
            screenshot_mode = config.get('screenshot_mode', 'BitBlt')
            
            # Convert mode string to expected format
            if 'PrintWindow' in screenshot_mode:
                mode = 'PrintWindow'
            else:
                mode = 'BitBlt'
            
            # Use callback function to capture screen region
            screenshot = self.capture_callback(
                self.capture_area['x'],
                self.capture_area['y'],
                self.capture_area['width'],
                self.capture_area['height'],
                mode,
                self.target_window_name
            )
            
            return screenshot
            
        except Exception as e:
            if not hasattr(self, '_capture_error_count'):
                self._capture_error_count = 0
            self._capture_error_count += 1
            
            if self._capture_error_count % 10 == 1:
                self.logger.error(f"æˆªå›¾å¤±è´¥ (ç¬¬{self._capture_error_count}æ¬¡): {e}")
            
            return None
    
    def _run_yolo_inference(self, image: np.ndarray) -> List[Dict]:
        try:
            results = self.model(image, verbose=False)
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for i in range(len(boxes)):
                        confidence = float(boxes.conf[i])
                        if confidence >= self.confidence_threshold:
                            detections.append({
                                'class': int(boxes.cls[i]),
                                'bbox': boxes.xyxy[i].cpu().numpy(),
                                'confidence': confidence
                            })
            return detections
        except Exception as e:
            self.logger.error(f"YOLOæ¨ç†å¤±è´¥: {e}")
            return []
    
    def _apply_tracking_algorithm(self, raw_detections: List[Dict]) -> Tuple[bool, Optional[Tuple[int, int, int]]]:
        """
        é‡å†™çš„è¿½è¸ªç®—æ³•ï¼šæ™ºèƒ½è°ƒè¯•è¾“å‡ºï¼Œæ”¯æŒç®€æ´å’Œè¯¦ç»†ä¸¤ç§æ¨¡å¼
        """
        # ä½¿ç”¨æ–°çš„èšç±»ç®—æ³•
        candidate_clusters = cluster_detections_to_rich_clusters(raw_detections)
        best_cluster, selection_details = find_best_coordinate_cluster(candidate_clusters)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¦ç»†è°ƒè¯•
        verbose_debug = self.config_dict.get('advanced_ocr_settings', {}).get('verbose_debug', False)
        
        detection_count = len(raw_detections)
        cluster_count = len(candidate_clusters)
        
        if verbose_debug:
            # è¯¦ç»†æ¨¡å¼ï¼šå®Œæ•´çš„è°ƒè¯•ä¿¡æ¯
            debug_info = f"=== è¯¦ç»†OCRè°ƒè¯• [{self.recognition_state}] ===\n"
            debug_info += f"åŸå§‹æ£€æµ‹: {detection_count}ä¸ªå­—ç¬¦\n"
            
            # å­—ç¬¦æ£€æµ‹è¯¦æƒ…
            if raw_detections:
                char_details = []
                for i, det in enumerate(raw_detections):
                    char = self._class_id_to_char_static(det['class']) or '?'
                    conf = det['confidence']
                    x1, y1, x2, y2 = det['bbox']
                    char_details.append(f"'{char}'({conf:.2f}@{int(x1)})")
                debug_info += f"å­—ç¬¦è¯¦æƒ…: {' '.join(char_details)}\n"
            
            # èšç±»åˆ†æè¿‡ç¨‹
            debug_info += f"\næ™ºèƒ½èšç±»: {cluster_count}ä¸ªèšç±»\n"
            for i, cluster in enumerate(candidate_clusters):
                word = cluster['word']
                detections_in_cluster = cluster.get('detections', [])
                debug_info += f"èšç±»{i+1}: '{word}' ({len(detections_in_cluster)}ä¸ªå­—ç¬¦)\n"
            
            # åæ ‡é€‰æ‹©åˆ†æ
            debug_info += f"\nåæ ‡é€‰æ‹©åˆ†æ:\n"
            for detail in selection_details:
                word = detail['cleaned']
                matched = detail['matched']
                reason = detail['reason']
                status = "âœ“" if matched else "âœ—"
                debug_info += f"'{word}': {reason} {status}\n"
            
            # é€‰æ‹©ç»“æœ
            if best_cluster:
                selected_word = best_cluster['word'].replace(" ", "").replace("\t", "")
                debug_info += f"\næœ€ç»ˆé€‰æ‹©: '{selected_word}' âœ“"
            else:
                debug_info += f"\næœ€ç»ˆé€‰æ‹©: æ— åŒ¹é…åæ ‡æ ¼å¼ âœ—"
        else:
            # ç®€æ´æ¨¡å¼ï¼šåªæ˜¾ç¤ºå…³é”®ä¿¡æ¯
            debug_info = f"OCR [{self.recognition_state}]: {detection_count}å­—ç¬¦ -> {cluster_count}èšç±»"
            
            if candidate_clusters:
                cluster_words = [f"'{cluster['word']}'" for cluster in candidate_clusters]
                debug_info += f" | {' '.join(cluster_words)}"
            
            if best_cluster:
                selected_word = best_cluster['word'].replace(" ", "").replace("\t", "")
                debug_info += f" -> '{selected_word}' âœ“"
            else:
                debug_info += f" -> æ— åŒ¹é… âœ—"
        
        success_this_frame = False
        new_coords = None

        if self.recognition_state == RecognitionState.LOCKED:
            success_this_frame, new_coords = self._handle_locked_state(raw_detections, best_cluster)
        elif self.recognition_state in [RecognitionState.SEARCHING, RecognitionState.LOST]:
            success_this_frame, new_coords = self._handle_searching_state(best_cluster)

        # æœ€ç»ˆçŠ¶æ€æ›´æ–°ä¸ä¿¡å·å‘å°„
        if success_this_frame and new_coords is not None:
            self.consecutive_failures = 0
            self.last_valid_coord = new_coords
            if self.recognition_state != RecognitionState.LOCKED:
                self._transition_to_locked()
            # å‘å°„åæ ‡ä¿¡å·
            self.coordinates_detected.emit(*new_coords)
            # å‘å°„æˆåŠŸçš„åæ ‡ç»“æœ
            final_output = f"âœ“ åæ ‡: ({new_coords[0]}, {new_coords[1]}, {new_coords[2]})"
            self.ocr_output_updated.emit(final_output)
        else:
            self.consecutive_failures += 1
            if self.recognition_state == RecognitionState.LOCKED and self.consecutive_failures >= self.lost_threshold_frames:
                self._transition_to_lost()
            # æ ¹æ®è°ƒè¯•æ¨¡å¼å‘å°„å¯¹åº”çš„ä¿¡æ¯
            self.ocr_output_updated.emit(debug_info)
        
        return success_this_frame, new_coords
    
    def _handle_locked_state(self, raw_detections: List[Dict], best_cluster: Optional[Dict]) -> Tuple[bool, Optional[Tuple[int, int, int]]]:
        """å¤„ç†LOCKEDçŠ¶æ€ï¼šä½¿ç”¨æœ€ä½³åæ ‡èšç±»è¿›è¡Œè§£æ"""
        if best_cluster:
            detections = best_cluster['detections']
            is_valid, parsed_coords = self._parse_and_validate_from_detections(detections)
            if is_valid and not self._is_teleport_jump(parsed_coords):
                self.last_valid_detections = detections  # æ›´æ–°æ¨¡æ¿
                return True, parsed_coords
        
        return False, None
    
    def _handle_searching_state(self, best_cluster: Optional[Dict]) -> Tuple[bool, Optional[Tuple[int, int, int]]]:
        """å¤„ç†SEARCHING/LOSTçŠ¶æ€ï¼šå°è¯•ä»æœ€ä½³èšç±»ä¸­æå–åæ ‡"""
        if best_cluster:
            detections = best_cluster['detections']
            is_valid, parsed_coords = self._parse_and_validate_from_detections(detections)
            if is_valid:
                self.last_valid_detections = detections # åˆå§‹åŒ–æ–°æ¨¡æ¿
                return True, parsed_coords
        return False, None
    
    def _is_teleport_jump(self, coordinates: Tuple[int, int, int]) -> bool:
        """Check if coordinate change exceeds maximum speed threshold"""
        if not self.last_valid_coord:
            return False
        
        # Calculate differences
        dx = coordinates[0] - self.last_valid_coord[0]
        dy = coordinates[1] - self.last_valid_coord[1]
        dz = coordinates[2] - self.last_valid_coord[2]
        
        # Calculate 2D horizontal distance (X, Y only)
        horizontal_distance = math.sqrt(dx*dx + dy*dy)
        
        # Zè½´(é«˜åº¦)å¼‚å¸¸æ£€æµ‹
        if abs(dz) > self.z_axis_threshold:
            return True
        
        # æ°´å¹³ç§»åŠ¨æ£€æµ‹
        if horizontal_distance > self.max_speed_threshold:
            return True
        
        return False
    
    def _transition_to_locked(self):
        """Transition to LOCKED state"""
        if self.recognition_state != RecognitionState.LOCKED:
            self.recognition_state = RecognitionState.LOCKED
            self.recognition_state_changed.emit(RecognitionState.LOCKED)
            self.logger.info(f"[STATE_CHANGE] -> LOCKED")
    
    def _transition_to_lost(self):
        """Transition to LOST state"""
        if self.recognition_state != RecognitionState.LOST:
            self.recognition_state = RecognitionState.LOST
            self.recognition_state_changed.emit(RecognitionState.LOST)
            self.logger.warning(f"[STATE_CHANGE] -> LOST (è¿ç»­å¤±è´¥: {self.consecutive_failures})")
    
    def _transition_to_searching(self):
        """Transition to SEARCHING state"""
        if self.recognition_state != RecognitionState.SEARCHING:
            self.recognition_state = RecognitionState.SEARCHING
            self.recognition_state_changed.emit(RecognitionState.SEARCHING)
            self.logger.info(f"[STATE_CHANGE] -> SEARCHING")
    
    def get_current_state(self) -> str:
        """Get current recognition state"""
        return self.recognition_state
    
    def get_last_coordinates(self) -> Optional[Tuple[int, int, int]]:
        """Get last valid coordinates"""
        return self.last_valid_coord
    
    def update_confidence_threshold(self, threshold: float):
        """Update confidence threshold dynamically"""
        self.confidence_threshold = threshold
        self.logger.info(f"ç½®ä¿¡ç‡é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold:.2f}")
    
    def update_interval(self, interval: int):
        """Update OCR recognition interval"""
        self.ocr_interval = interval
        self.logger.info(f"OCRè¯†åˆ«é—´éš”å·²æ›´æ–°ä¸º: {interval}ms")
    
    def update_advanced_parameters(self, params: Dict[str, Any]):
        """Update advanced OCR parameters dynamically"""
        try:
            if 'confidence_threshold' in params:
                self.confidence_threshold = params['confidence_threshold']
                self.logger.debug(f"ç½®ä¿¡åº¦é˜ˆå€¼æ›´æ–°ä¸º: {self.confidence_threshold}")
            
            if 'max_speed_threshold' in params:
                self.max_speed_threshold = params['max_speed_threshold']
                self.logger.debug(f"æœ€å¤§é€Ÿåº¦é˜ˆå€¼æ›´æ–°ä¸º: {self.max_speed_threshold}")
            
            if 'ema_alpha' in params:
                self.ema_alpha = params['ema_alpha']
                self.logger.debug(f"EMAå¹³æ»‘å› å­æ›´æ–°ä¸º: {self.ema_alpha}")
            
            if 'lost_threshold_frames' in params:
                self.lost_threshold_frames = params['lost_threshold_frames']
                self.logger.debug(f"ä¸¢å¤±é˜ˆå€¼å¸§æ•°æ›´æ–°ä¸º: {self.lost_threshold_frames}")
            
            if 'z_axis_threshold' in params:
                self.z_axis_threshold = params['z_axis_threshold']
                self.logger.debug(f"Zè½´å¼‚å¸¸é˜ˆå€¼æ›´æ–°ä¸º: {self.z_axis_threshold}")
            
            # å…¶ä»–é«˜çº§å‚æ•°ï¼ˆè¿™äº›å‚æ•°åœ¨å‡½æ•°ä¸­åŠ¨æ€è¯»å–ï¼‰
            if 'char_spacing_threshold' in params:
                self.logger.debug(f"å­—ç¬¦é—´è·é˜ˆå€¼è®¾ç½®ä¸º: {params['char_spacing_threshold']}")
            
            if 'smart_split_threshold' in params:
                self.logger.debug(f"æ™ºèƒ½åˆ†å‰²é˜ˆå€¼è®¾ç½®ä¸º: {params['smart_split_threshold']}")
            
            if 'verbose_diagnostics' in params:
                self.logger.debug(f"è¯¦ç»†è¯Šæ–­è®¾ç½®ä¸º: {params['verbose_diagnostics']}")
            
            self.logger.info(f"é«˜çº§OCRå‚æ•°å·²æ›´æ–°: {list(params.keys())}")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°é«˜çº§OCRå‚æ•°å¤±è´¥: {e}")
    
    def update_capture_settings(self, capture_area: Dict[str, int], interval: int, window_name: str):
        """Update capture settings"""
        self.capture_area = capture_area
        self.ocr_interval = interval
        self.target_window_name = window_name
        self.logger.info(f"æˆªå›¾è®¾ç½®å·²æ›´æ–°: åŒºåŸŸ{capture_area}, é—´éš”{interval}ms, çª—å£'{window_name}'")